<!DOCTYPE html>
<html lang="en">
<head>
    <title>Neo/Duo Web Demo</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" async crossorigin="anonymous" />
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <link href="./styles.css" rel="stylesheet">
    <link href="./menu.css" rel="stylesheet">
    <link rel='manifest' href='/manifest.json'>

</head>
<body>
    <div class="fold-tester"></div>
    <div class="menu sticky-top">
        <div class="left">
            <i class="fa fa-bars" aria-hidden="true"></i>
            <i class="fa fa-search" aria-hidden="true"></i>
        </div>
        <div class="center">AI Research Briefs</div>
        <div class="right">
            <mgt-login class="login-btn"></mgt-login>
        </div>
    </div>
    
    <div class="wrapper">
        <div class="article">
            <h1 class="headline display-5 font-weight-bold font-italic">AI improves medical image analysis for clinicians</h1>
            
            <div>
                <img class="img-fluid mt-3" src="./images/background.jpg" />
            </div>
            
            <p class="photo-caption mt-1 text-muted">
                Photo caption: AI improving medical image analysis.
            </p>
            <p class="mt-1">
                By <a href="#">Lana Marshall</a>
            </p>
            <div class="mt-1">
                February 11, 2020
            </div>
            
            <p class="article-text">We believe that AI offers incredible opportunities to drive widespread economic and social progress. The key to attaining these benefits is to develop AI in such a way that it is human-centered.</p>
            <p class="article-text">Put simply, we aim to develop AI in order to augment human abilities, especially humankind’s innate ingenuity. We want to combine the capabilities of computers with human capabilities to enable people to achieve more.</p>
            <p class="article-text">Computers are very good at remembering things. Absent a system failure, computers never forget. Computers are very good at probabilistic reasoning, something many people are not so good at.</p>
            <p class="article-text">Computers are very good at discerning patterns in data that are too subtle for people to notice. With these capabilities, computers can help us make better decisions.</p>
            <p class="article-text">And this is a real benefit, because, as researchers in cognitive psychology have established, human decisionmaking is often imperfect.</p>
            <p class="article-text">Broadly speaking, the kind of “computational intelligence” that computers can provide will have a significant impact in almost any field where intelligence itself has a role to play.</p>
            <p class="article-text">AI systems are already helping people tackle big problems. A good example of this is “InnerEye,” a project in which U.K.-based researchers at Microsoft have teamed up with oncologists to develop an AI system to help treat cancer more effectively.</p>
            <p class="article-text">InnerEye uses AI technology originally developed for video gameplay to analyze computed tomography (CT) and magnetic resonance imaging (MRI), and helps oncologists target cancer treatment more quickly.</p>
            <p class="article-text">CT and MRI scans allow doctors to look inside a patient’s body in three dimensions and study anomalies, such as tumors. For cancer patients who are undergoing radiation therapy, oncologists use such scans to delineate tumors from the surrounding healthy tissue, bone and organs.</p>
            <p class="article-text">In turn, this helps focus the cell-damaging radiation treatment on the tumor while avoiding healthy anatomy as much as possible. Today, this 3-D delineation task is manual, slow and error-prone. It requires a radiation oncologist to draw contours on hundreds of cross-sectional images by hand, one at a time — a process that can take hours.</p>
            <p class="article-text">InnerEye is being designed to accomplish the same task in a fraction of that time, while giving oncologists full control over the accuracy of the final delineation.</p>
            <p class="article-text">To create InnerEye’s automatic segmentation, researchers used hundreds of raw CT and MRI scans (with all identifying patient information removed).</p>
            <p class="article-text">The scans were fed into an AI system that learned to recognize tumors and healthy anatomical structures with a clinical level of accuracy.</p>
            <p class="article-text">As part of the process, once the InnerEye automatic segmentation is complete, the oncologist goes in to fine-tune the contours.</p>
            <p class="article-text">The doctor is in control at all times. With further advances, InnerEye may be helpful for measuring and tracking tumor changes over time, and even assessing whether a treatment is working.</p>
            <p class="article-text">Another interesting example is “Project Premonition.” We’ve all seen the heartbreaking stories of lives lost in recent years to dangerous diseases like Zika, Ebola and dengue that are transmitted from animals and insects to people.</p>
            <p class="article-text">Today, epidemiologists often don’t learn about the emergence of these pathogens until an outbreak is underway. But this project — developed by scientists and engineers at Microsoft Research, the University of Pittsburgh, the University of California Riverside and Vanderbilt University — is exploring ways to detect pathogens in the environment so public health officials can protect people from transmission before an outbreak begins.</p>
            <p class="article-text">What epidemiologists need are sensors that can detect when pathogens are present. The researchers on this project hit upon an ingenious idea: why not use mosquitoes as sensors?</p>
            <p class="article-text">There are plenty of them and they feed on a wide range of animals, extracting a small amount of blood that contains genetic information about the animal bitten and pathogens circulating in the environment.</p>
            <p class="article-text">The researchers use advanced autonomous drones capable of navigating through complex environments to identify areas where mosquitoes breed.</p>
            <p class="article-text">They then deploy robotic traps that can distinguish between the types of mosquitoes researchers want to collect and other insects, based on wing movement patterns.</p>
            <p class="article-text">Once specimens are collected, cloud-scale genomics and advanced AI systems identify the animals that the mosquitoes have fed on and the pathogens that the animals carry.</p>
            <p class="article-text">In the past, this kind of genetic analysis could take a month; now the AI capabilities of Project Premonition have shortened that to about 12 hours.</p>

            <div class="mt-5 w-100">
                <button class="btn btn-block btn-secondary">Show 89 comments <i class="fa fa-commenting-o"></i></button>
            </div>

            <div class="w-100">
                <hr class="mt-5" />
            </div>
            <div class="row mb-5 w-100 p-0">
                <div class="col-3">
                    <p class="category">CATEGORY ONE</p>
                    <p>Link 1</p>
                    <p>Link 2</p>
                    <p>Link 3</p>
                    <p>Link 4</p>
                    <p>Link 5</p>
                </div>
                <div class="col-3">
                    <p class="category">CATEGORY TWO</p>
                    <p>Link 1</p>
                    <p>Link 2</p>
                    <p>Link 3</p>
                    <p>Link 4</p>
                    <p>Link 5</p>
                </div>
                <div class="col-3">
                    <p class="category">CATEGORY THREE</p>
                    <p>Link 1</p>
                    <p>Link 2</p>
                    <p>Link 3</p>
                    <p>Link 4</p>
                    <p>Link 5</p>
                </div>
                <div class="col-3">
                    <p class="category">CATEGORY FOUR</p>
                    <p>Link 1</p>
                    <p>Link 2</p>
                    <p>Link 3</p>
                    <p>Link 4</p>
                    <p>Link 5</p>
                </div>
            </div>
        </div>

        <!-- Add our paging buttons. Visible only when spanning. -->
        <button class="btn btn-link paging-btn paging-btn-left">
            <span class="fa-stack fa-lg" aria-hidden="true">
                <i class="fa fa-circle fa-stack-2x"></i>
                <i class="fa fa-angle-left fa-stack-1x fa-inverse"></i>
            </span>
        </button>
        <button class="btn btn-link paging-btn paging-btn-right">
            <span class="fa-stack fa-lg" aria-hidden="true">
                <i class="fa fa-circle fa-stack-2x"></i>
                <i class="fa fa-angle-right fa-stack-1x fa-inverse"></i>
            </span>
        </button>
    </div>

    <!-- For login button, use Graph Toolkit -->
    <script src="https://unpkg.com/@microsoft/mgt/dist/bundle/mgt-loader.js"></script>
    <mgt-msal-provider client-id="1a61b651-7860-4bf8-94d0-d49bf45dcf67"></mgt-msal-provider>

    <!-- Polyfills for dual screen capabilities -->
    <script src="./spanning-css-polyfill.js"></script>
    <script src="./window-segments-polyfill.js"></script>
    <script>

        // Check compatibility for the browser we're running this in
        if ("serviceWorker" in navigator) {
            if (navigator.serviceWorker.controller) {
                console.log("[PWA Builder] active service worker found, no need to register");
            } else {
                // Register the service worker
                navigator.serviceWorker.register("pwabuilder-sw.js", {
                    scope: "./"
                })
                .then(function (reg) {
                    console.log("[PWA Builder] Service worker has been registered for scope: " + reg.scope);
                });
            }
        }

        function fakeSetSpanningMode(spanningOrNull) {
            const config = window["__foldables_env_vars__"];
            if (!spanningOrNull) {
                // Then toggle it.
                spanningOrNull = config.spanning === "none" ? "single-fold-vertical" : "none";
            }

            config.update({
                //spanning: "none",
                spanning: spanningOrNull, 
                foldSize: 30
            });
        }
        
        var currentPage = 0;
        function scrollToPage(pageNumber) {
            currentPage = pageNumber;

            // Scroll over to that page.
            const article = document.querySelector(".article");
            const wrapper = document.querySelector(".wrapper");
            const foldWidth = window["__foldables_env_vars__"].foldSize;
            const screenWidth = document.querySelector(".article-text").scrollWidth + foldWidth;
            wrapper.scrollLeft = screenWidth * pageNumber;
            
            // Hide the "page left" button if we're on the first page (page zero).
            document.querySelector(".paging-btn-left").style.visibility = pageNumber === 0 ? "hidden" : "visible";
        }

        function printWindowSegments() {
            const screens = window.getWindowSegments();
            console.log("Window segments:")
            console.table(screens);
            console.log("Window size:", window.innerWidth, window.innerHeight);
        }

        // Clicking the menu at the top left toggles spanning.
        document.querySelector(".fa-bars").addEventListener("click", () => fakeSetSpanningMode(null));

        // Clicking the paging buttons scroll to the desired page.
        document.querySelector(".paging-btn-left").addEventListener("click", () => scrollToPage(currentPage - 1));
        document.querySelector(".paging-btn-right").addEventListener("click", () => scrollToPage(currentPage + 1));

        // See how many screens we have. If we have 2, go into spanning mode.
        // const screens = window["getWindowSegments"]();
        // if (screens.length > 1) {
        //     fakeSetSpanningMode("single-fold-vertical");
        // }

        window.addEventListener("resize", () => {
            console.log("resized");
            printWindowSegments();
        });
        printWindowSegments();

    </script>

</body>
</html>